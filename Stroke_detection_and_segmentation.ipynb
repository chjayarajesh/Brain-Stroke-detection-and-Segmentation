{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyM+kmO//oWUmHnmuM0vcaCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chjayarajesh/Brain-Stroke-detection-and-Segmentation/blob/main/Stroke_detection_and_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Brain Stroke classification and segmentation**"
      ],
      "metadata": {
        "id": "Y4cQIIfNkHGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Kaggle API to import dataset**"
      ],
      "metadata": {
        "id": "RhDyvyFDi7K5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxmYnr38hDt0"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle timm\n",
        "\n",
        "# Upload kaggle.json from your Kaggle account (Account → API → Create New Token)\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Move kaggle.json to correct path\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading Dataset"
      ],
      "metadata": {
        "id": "RGINQi4DjBp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Brain Stroke CT Dataset\n",
        "!kaggle datasets download -d ozguraslank/brain-stroke-ct-dataset -p /content/dataset\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -q /content/dataset/brain-stroke-ct-dataset.zip -d /content/dataset"
      ],
      "metadata": {
        "id": "DaLietIahcHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Segregation and splitting into (Train, validate and test)**"
      ],
      "metadata": {
        "id": "CIKaKKGv_FKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2  # Added import for OpenCV\n",
        "\n",
        "# Step 1: Segregate images and overlays into train, val, test\n",
        "def segregate_dataset(base_dir, classes, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    for cls in classes:\n",
        "        png_dir = os.path.join(base_dir, cls, 'PNG')\n",
        "        overlay_dir = os.path.join(base_dir, cls, 'OVERLAY')\n",
        "        if not os.path.exists(png_dir):\n",
        "            print(f\"PNG folder not found for {cls}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Get list of PNG images\n",
        "        images = [os.path.join(png_dir, f) for f in os.listdir(png_dir) if f.lower().endswith('.png')]\n",
        "        if len(images) == 0:\n",
        "            print(f\"No PNG images found for {cls}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Split into train/val/test\n",
        "        train_images, test_images = train_test_split(images, test_size=val_ratio + test_ratio, random_state=42)\n",
        "        val_images, test_images = train_test_split(test_images, test_size=test_ratio / (val_ratio + test_ratio), random_state=42)\n",
        "\n",
        "        # Create directories for PNG and OVERLAY\n",
        "        for split, split_images in [('train', train_images), ('val', val_images), ('test', test_images)]:\n",
        "            split_png_dir = os.path.join(base_dir, split, 'PNG', cls)\n",
        "            split_overlay_dir = os.path.join(base_dir, split, 'OVERLAY', cls)\n",
        "            os.makedirs(split_png_dir, exist_ok=True)\n",
        "            os.makedirs(split_overlay_dir, exist_ok=True)\n",
        "\n",
        "            # Copy PNG images\n",
        "            for img in split_images:\n",
        "                filename = os.path.basename(img)\n",
        "                shutil.copy(img, os.path.join(split_png_dir, filename))\n",
        "\n",
        "            # Copy corresponding OVERLAY images or create zero mask for Normal\n",
        "            for img in split_images:\n",
        "                filename = os.path.basename(img)\n",
        "                overlay_path = os.path.join(overlay_dir, filename)\n",
        "                if os.path.exists(overlay_path):\n",
        "                    shutil.copy(overlay_path, os.path.join(split_overlay_dir, filename))\n",
        "                elif cls == 'Normal' and not os.path.exists(overlay_dir):\n",
        "                    # Create a zero mask for Normal if no overlay exists\n",
        "                    zero_mask = np.zeros((256, 256), dtype=np.uint8)  # Adjust size if needed\n",
        "                    cv2.imwrite(os.path.join(split_overlay_dir, filename), zero_mask)\n",
        "                    print(f\"Created zero mask for {filename} in {cls}\")\n",
        "                else:\n",
        "                    print(f\"Overlay not found for {filename}, skipping copy.\")\n",
        "\n",
        "        print(f\"{cls}: Train {len(train_images)}, Val {len(val_images)}, Test {len(test_images)}\")\n",
        "\n",
        "# Base directory (adjust to your Colab path)\n",
        "base_dir = '/content/dataset/Brain_Stroke_CT_Dataset'  # Update to your actual path\n",
        "classes = ['Bleeding', 'Ischemia', 'Normal']  # Adjust based on your dataset\n",
        "\n",
        "# Run segregation\n",
        "segregate_dataset(base_dir, classes)"
      ],
      "metadata": {
        "id": "oW498DegstQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Classification Model training**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Preproccesing and augmentation of dataset\n",
        "\n",
        "---\n",
        "\n",
        "ConvNext model -(Convolutional Next)\n"
      ],
      "metadata": {
        "id": "A_Nm5MdejFoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "base_dir = '/content/dataset/Brain_Stroke_CT_Dataset'  # Update to your actual path in Colab\n",
        "\n",
        "# Step 2: Preprocessing and Training\n",
        "# Custom transform to replicate grayscale to 3 channels\n",
        "class GrayscaleToRGB:\n",
        "    def __call__(self, image):\n",
        "        if image.shape[0] == 1:\n",
        "            return torch.cat([image] * 3, dim=0)\n",
        "        return image\n",
        "\n",
        "# Custom Dataset with 3-channel replication\n",
        "class CTDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.class_names = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.class_names)}\n",
        "\n",
        "        for cls_name in self.class_names:\n",
        "            cls_dir = os.path.join(data_dir, cls_name)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                for img_name in os.listdir(cls_dir):\n",
        "                    img_path = os.path.join(cls_dir, img_name)\n",
        "                    if os.path.isfile(img_path):\n",
        "                        self.images.append(img_path)\n",
        "                        self.labels.append(self.class_to_idx[cls_name])\n",
        "        if not self.images:\n",
        "            raise ValueError(f\"No images found in {data_dir}. Check your dataset path and ensure it contains image subfolders.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('L')  # Load as grayscale\n",
        "            if self.transform:\n",
        "                image = self.transform(image)  # Apply full transform pipeline\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            return torch.zeros(3, 224, 224), label  # Return 3-channel placeholder\n",
        "\n",
        "# Load datasets (after segregation, use the train/val/test directories)\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    GrayscaleToRGB(),  # Replicate to 3 channels after ToTensor\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 3-channel normalization\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    GrayscaleToRGB(),  # Replicate to 3 channels after ToTensor\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dataset = CTDataset(train_dir, transform=train_transform)\n",
        "val_dataset = CTDataset(val_dir, transform=val_test_transform)\n",
        "test_dataset = CTDataset(test_dir, transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "print(f\"Classes: {train_dataset.class_names}\")\n",
        "\n",
        "# Set device\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load pre-trained ConvNeXt-Base model\n",
        "model = timm.create_model('convnext_base', pretrained=True)\n",
        "model.reset_classifier(num_classes=3)  # 3 classes: hemorrhagic, ischemic, normal\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    best_acc = 0.0\n",
        "    val_accuracies = []\n",
        "    val_precisions = []\n",
        "    val_recalls = []\n",
        "    val_f1_scores = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        print(f\"Starting epoch {epoch + 1}/{num_epochs}\")\n",
        "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\") as pbar:\n",
        "            for i, (inputs, labels) in enumerate(train_loader):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "                pbar.update(1)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_val_loss = val_loss / len(val_loader)\n",
        "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "        epoch_precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "        epoch_recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "        val_accuracies.append(epoch_acc)\n",
        "        val_precisions.append(epoch_precision)\n",
        "        val_recalls.append(epoch_recall)\n",
        "        val_f1_scores.append(epoch_f1)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_acc:.4f}, Precision: {epoch_precision:.4f}, Recall: {epoch_recall:.4f}, F1: {epoch_f1:.4f}')\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), 'best_model_3class.pth')\n",
        "\n",
        "    # Plot graphs for 4 parameters\n",
        "    epochs = range(1, num_epochs + 1)\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    fig.suptitle('Validation Metrics Over Epochs')\n",
        "\n",
        "    # Accuracy graph\n",
        "    axs[0, 0].plot(epochs, val_accuracies, label='Accuracy', color='b')\n",
        "    axs[0, 0].set_title('Accuracy')\n",
        "    axs[0, 0].set_xlabel('Epoch')\n",
        "    axs[0, 0].set_ylabel('Score')\n",
        "    axs[0, 0].legend()\n",
        "\n",
        "    # Precision graph\n",
        "    axs[0, 1].plot(epochs, val_precisions, label='Precision', color='r')\n",
        "    axs[0, 1].set_title('Precision')\n",
        "    axs[0, 1].set_xlabel('Epoch')\n",
        "    axs[0, 1].set_ylabel('Score')\n",
        "    axs[0, 1].legend()\n",
        "\n",
        "    # Recall graph\n",
        "    axs[1, 0].plot(epochs, val_recalls, label='Recall', color='g')\n",
        "    axs[1, 0].set_title('Recall')\n",
        "    axs[1, 0].set_xlabel('Epoch')\n",
        "    axs[1, 0].set_ylabel('Score')\n",
        "    axs[1, 0].legend()\n",
        "\n",
        "    # F1 Score graph\n",
        "    axs[1, 1].plot(epochs, val_f1_scores, label='F1 Score', color='m')\n",
        "    axs[1, 1].set_title('F1 Score')\n",
        "    axs[1, 1].set_xlabel('Epoch')\n",
        "    axs[1, 1].set_ylabel('Score')\n",
        "    axs[1, 1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('validation_metrics_graphs.png')  # Save the figure\n",
        "    plt.show()\n",
        "    return val_accuracies, val_precisions, val_recalls, val_f1_scores\n",
        "\n",
        "# Evaluate function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "    print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Hemorrhagic', 'Ischemic', 'Normal'], yticklabels=['Hemorrhagic', 'Ischemic', 'Normal'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.savefig('confusion_matrix.png')  # Save the confusion matrix\n",
        "    plt.show()\n",
        "\n",
        "# Train the model and get metrics\n",
        "val_accuracies, val_precisions, val_recalls, val_f1_scores = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Load best model and evaluate\n",
        "model.load_state_dict(torch.load('best_model_3class.pth'))\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "id": "_BFU8C-HerQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentation Model training**\n",
        "---\n",
        "\n",
        "\n",
        "Preproccesing and augmentation of dataset\n",
        "\n",
        "---\n",
        "\n",
        "U-Net with efficientnet-b4 encoder"
      ],
      "metadata": {
        "id": "yTQb7Szvfzcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install segmentation-models-pytorch -q\n",
        "\n",
        "# Step 3: Preprocessing and Training\n",
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch\n",
        "import torch.optim as optim  # Added import\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    BATCH_SIZE = 8\n",
        "    IMG_HEIGHT = 256\n",
        "    IMG_WIDTH = 256\n",
        "    EPOCHS = 50\n",
        "    LEARNING_RATE = 1e-4\n",
        "    DATASET_PATH = '/content/brain-stroke-images'  # Root path\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    NUM_WORKERS = 2\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Preprocessing: Generate pseudo-masks for stroke images\n",
        "def generate_pseudo_mask(image, threshold=0.1):  # Simple thresholding\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, threshold * 255, 255, cv2.THRESH_BINARY)\n",
        "    mask = mask / 255.0\n",
        "    return mask.astype(np.float32)\n",
        "\n",
        "# Load data from cropped folders\n",
        "def load_segmentation_data(base_dir):\n",
        "    image_paths = []\n",
        "    mask_paths = []  # Pseudo-masks generated on-the-fly\n",
        "    labels = []  # 1 for STROKE, 0 for NORMAL\n",
        "\n",
        "    for split in ['TRAIN_CROP', 'VAL_CROP', 'TEST_CROP']:\n",
        "        for category in ['NORMAL', 'STROKE']:\n",
        "            category_dir = os.path.join(base_dir, 'stroke_cropped/CROPPED', split, category)\n",
        "            if os.path.exists(category_dir):\n",
        "                images = glob(os.path.join(category_dir, '*.jpg'))\n",
        "                for img in images:\n",
        "                    image_paths.append(img)\n",
        "                    mask_paths.append(None)  # Will generate pseudo-mask\n",
        "                    labels.append(1 if category == 'STROKE' else 0)\n",
        "\n",
        "    print(f\"Loaded {len(image_paths)} images: {np.sum(labels)} stroke, {len(labels) - np.sum(labels)} normal.\")\n",
        "    return image_paths, mask_paths, labels\n",
        "\n",
        "image_paths, mask_paths, labels = load_segmentation_data(config.DATASET_PATH)\n",
        "if len(image_paths) == 0:\n",
        "    raise ValueError(\"No images found! Check dataset path.\")\n",
        "\n",
        "# Split into train/val/test\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=42, stratify=test_labels)\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n",
        "print(f\"Test samples: {len(test_images)}\")\n",
        "\n",
        "# Dataset class\n",
        "class StrokeDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transforms=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.image_paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (config.IMG_WIDTH, config.IMG_HEIGHT))\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        if label == 1:  # Stroke: generate pseudo-mask\n",
        "            msk = generate_pseudo_mask(img, threshold=0.1)\n",
        "        else:  # Normal: zero mask\n",
        "            msk = np.zeros((config.IMG_HEIGHT, config.IMG_WIDTH), dtype=np.float32)\n",
        "\n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image=img, mask=msk)\n",
        "            img, msk = transformed['image'], transformed['mask']\n",
        "\n",
        "        return img, msk\n",
        "\n",
        "# Transforms\n",
        "def get_transforms(is_training=True):\n",
        "    if is_training:\n",
        "        return A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=0.3),\n",
        "            A.Affine(translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)}, scale=(0.95, 1.05), rotate=(-5, 5), p=0.3),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "train_dataset = StrokeDataset(train_images, train_labels, get_transforms(True))\n",
        "val_dataset = StrokeDataset(val_images, val_labels, get_transforms(False))\n",
        "test_dataset = StrokeDataset(test_images, test_labels, get_transforms(False))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# Segmentation Model\n",
        "model = smp.Unet(\n",
        "    encoder_name='efficientnet-b4',\n",
        "    encoder_weights='imagenet',\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        "    activation=None,\n",
        ").to(config.DEVICE)\n",
        "\n",
        "# Loss and Optimizer\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "    def forward(self, y_pred_prob, y_true):\n",
        "        y_pred = y_pred_prob.view(-1)\n",
        "        y_true = y_true.view(-1)\n",
        "        intersection = (y_pred * y_true).sum()\n",
        "        dice = (2. * intersection + self.smooth) / (y_pred.sum() + y_true.sum() + self.smooth)\n",
        "        return 1 - dice\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "    def forward(self, y_pred_logits, y_true):\n",
        "        prob = torch.sigmoid(y_pred_logits)\n",
        "        return 0.5 * self.bce(y_pred_logits, y_true) + 0.5 * self.dice(prob, y_true)\n",
        "\n",
        "criterion = CombinedLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)  # Now should work\n",
        "\n",
        "# Training\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = running_dice = running_iou = 0.0\n",
        "    progress_bar = tqdm(dataloader, desc='Training')\n",
        "    for batch_idx, (images, masks) in enumerate(progress_bar):\n",
        "        images = images.to(device)\n",
        "        masks = masks.unsqueeze(1).to(device)\n",
        "\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        dice_score = calculate_dice_score(probs, masks)\n",
        "        iou_score = calculate_iou_score(probs, masks)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_dice += dice_score\n",
        "        running_iou += iou_score\n",
        "\n",
        "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Dice': f'{dice_score:.4f}', 'IoU': f'{iou_score:.4f}'})\n",
        "\n",
        "    N = len(dataloader)\n",
        "    return running_loss / N, running_dice / N, running_iou / N\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = running_dice = running_iou = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.unsqueeze(1).to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, masks)\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "            dice_score = calculate_dice_score(probs, masks)\n",
        "            iou_score = calculate_iou_score(probs, masks)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_dice += dice_score\n",
        "            running_iou += iou_score\n",
        "\n",
        "    N = len(dataloader)\n",
        "    return running_loss / N, running_dice / N, running_iou / N\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50):\n",
        "    best_dice = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        train_loss, train_dice, train_iou = train_epoch(model, train_loader, criterion, optimizer, config.DEVICE)\n",
        "        val_loss, val_dice, val_iou = validate_epoch(model, val_loader, criterion, config.DEVICE)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, Train IoU: {train_iou:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, Val IoU: {val_iou:.4f}\")\n",
        "\n",
        "        if val_dice > best_dice:\n",
        "            best_dice = val_dice\n",
        "            torch.save(model.state_dict(), 'best_stroke_segmentation_model.pth')\n",
        "            print(f\"New best model saved! Dice: {best_dice:.4f}\")\n",
        "\n",
        "    model.load_state_dict(torch.load('best_stroke_segmentation_model.pth'))\n",
        "    return model\n",
        "\n",
        "# Metrics\n",
        "def calculate_dice_score(y_pred_prob, y_true, smooth=1e-6):\n",
        "    y_pred = (y_pred_prob > 0.5).float()\n",
        "    intersection = (y_pred * y_true).sum()\n",
        "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
        "    return dice.item()\n",
        "\n",
        "def calculate_iou_score(y_pred_prob, y_true, smooth=1e-6):\n",
        "    y_pred = (y_pred_prob > 0.5).float()\n",
        "    intersection = (y_pred * y_true).sum()\n",
        "    union = y_pred.sum() + y_true.sum() - intersection\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return iou.item()\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
        "\n",
        "# Step 3: Show 2 Images After Segmentation\n",
        "def predict_and_show(model, image_paths, num_samples=2):\n",
        "    model.eval()\n",
        "    transforms = get_transforms(False)\n",
        "    for i in range(num_samples):\n",
        "        image = cv2.imread(image_paths[i])\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image_resized = cv2.resize(image_rgb, (config.IMG_WIDTH, config.IMG_HEIGHT))\n",
        "\n",
        "        transformed = transforms(image=image_resized, mask=np.zeros((config.IMG_HEIGHT, config.IMG_WIDTH), np.float32))\n",
        "        image_tensor = transformed['image'].unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_logits = model(image_tensor)[0, 0].cpu().numpy()\n",
        "            pred_prob = 1 / (1 + np.exp(-pred_logits))\n",
        "            pred_mask_binary = (pred_prob > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(pred_mask_binary, cmap='gray')\n",
        "        plt.title(f\"Segmented Image {i+1}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Use 2 images from test set\n",
        "predict_and_show(model, test_images, num_samples=2)"
      ],
      "metadata": {
        "id": "tY5Ht8CGf6SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **validation code for the classification model**"
      ],
      "metadata": {
        "id": "8c4kacyG4wuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install timm scikit-learn matplotlib seaborn -q\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from datetime import datetime\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ====================================================\n",
        "# CLASSIFICATION CONFIGURATION\n",
        "# ====================================================\n",
        "\n",
        "class ClassificationConfig:\n",
        "    BASE_DIR = '/content/dataset/Brain_Stroke_CT_Dataset'\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    NUM_WORKERS = 2\n",
        "    CLASSES = ['Bleeding', 'Ischemia', 'Normal']\n",
        "    MODEL_PATH = 'best_model_3class.pth'\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "config = ClassificationConfig()\n",
        "print(f\"🔧 Classification validation - Using device: {config.DEVICE}\")\n",
        "\n",
        "# ====================================================\n",
        "# CLASSIFICATION DATASET\n",
        "# ====================================================\n",
        "\n",
        "class CTDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.class_names = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.class_names)}\n",
        "\n",
        "        for cls_name in self.class_names:\n",
        "            cls_dir = os.path.join(data_dir, cls_name)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                for img_name in os.listdir(cls_dir):\n",
        "                    img_path = os.path.join(cls_dir, img_name)\n",
        "                    if os.path.isfile(img_path) and img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        self.images.append(img_path)\n",
        "                        self.labels.append(self.class_to_idx[cls_name])\n",
        "\n",
        "        if not self.images:\n",
        "            raise ValueError(f\"No images found in {data_dir}. Check your dataset path.\")\n",
        "\n",
        "        print(f\"📊 Dataset loaded: {len(self.images)} images across {len(self.class_names)} classes\")\n",
        "        print(f\"🏷️  Classes: {self.class_names}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('L')  # Load as grayscale\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Error loading image {img_path}: {e}\")\n",
        "            # Return placeholder\n",
        "            return torch.zeros(3, 224, 224), label\n",
        "\n",
        "# Custom transform to replicate grayscale to 3 channels\n",
        "class GrayscaleToRGB:\n",
        "    def __call__(self, image):\n",
        "        if image.shape[0] == 1:\n",
        "            return torch.cat([image] * 3, dim=0)\n",
        "        return image\n",
        "\n",
        "# Classification transforms\n",
        "classification_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    GrayscaleToRGB(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load test dataset\n",
        "test_dir = os.path.join(config.BASE_DIR, 'test/PNG')\n",
        "print(f\"🔍 Loading classification test data from: {test_dir}\")\n",
        "\n",
        "classification_dataset = CTDataset(test_dir, classification_transform)\n",
        "classification_loader = DataLoader(\n",
        "    classification_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS\n",
        ")\n",
        "\n",
        "print(f\"✅ Classification test samples: {len(classification_dataset)}\")\n",
        "\n",
        "# ====================================================\n",
        "# CLASSIFICATION MODEL VALIDATION (FIXED)\n",
        "# ====================================================\n",
        "\n",
        "class ClassificationValidator:\n",
        "    def __init__(self, model_path, class_names):\n",
        "        \"\"\"Initialize classification validator\"\"\"\n",
        "        self.device = config.DEVICE\n",
        "        self.class_names = class_names\n",
        "        self.class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "        # Load model\n",
        "        self.model = timm.create_model('convnext_base', pretrained=False, num_classes=len(class_names))\n",
        "        if os.path.exists(model_path):\n",
        "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "            print(f\"✅ Classification model loaded from {model_path}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"❌ Classification model not found: {model_path}\")\n",
        "\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        print(f\"🔧 Classification validator initialized on {self.device}\")\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Run comprehensive classification validation - FIXED\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🔍 CLASSIFICATION MODEL VALIDATION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        all_filenames = []\n",
        "\n",
        "        print(f\"📊 Processing {len(classification_dataset)} test samples...\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm(classification_loader, desc=\"Validating\", unit=\"batch\")\n",
        "            for batch_idx, (images, labels) in enumerate(progress_bar):\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(images)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "                # Get filenames for first few batches\n",
        "                if batch_idx < 3:\n",
        "                    start_idx = batch_idx * config.BATCH_SIZE\n",
        "                    end_idx = min((batch_idx + 1) * config.BATCH_SIZE, len(classification_dataset.images))\n",
        "                    batch_filenames = [os.path.basename(img_path) for img_path in classification_dataset.images[start_idx:end_idx]]\n",
        "                    all_filenames.extend(batch_filenames)\n",
        "\n",
        "                # Progress update\n",
        "                if len(all_preds) % 100 == 0:\n",
        "                    batch_labels = np.array(all_labels[-100:])\n",
        "                    batch_preds = np.array(all_preds[-100:])\n",
        "                    batch_acc = accuracy_score(batch_labels, batch_preds)\n",
        "                    progress_bar.set_postfix({'Acc': f\"{batch_acc:.3f}\"})\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        all_labels_np = np.array(all_labels)\n",
        "        all_preds_np = np.array(all_preds)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels_np, all_preds_np)\n",
        "        precision = precision_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)\n",
        "        recall = recall_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(all_labels_np, all_preds_np, average='weighted', zero_division=0)\n",
        "        cm = confusion_matrix(all_labels_np, all_preds_np)\n",
        "\n",
        "        # Per-class metrics\n",
        "        class_accuracy = {}\n",
        "        class_support = {}\n",
        "        for i, class_name in enumerate(self.class_names):\n",
        "            class_mask = all_labels_np == i\n",
        "            class_support[class_name] = np.sum(class_mask)\n",
        "            if class_support[class_name] > 0:\n",
        "                class_acc = accuracy_score(all_labels_np[class_mask], all_preds_np[class_mask])\n",
        "                class_accuracy[class_name] = class_acc\n",
        "            else:\n",
        "                class_accuracy[class_name] = 0.0\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\n📊 OVERALL PERFORMANCE:\")\n",
        "        print(f\"{'Metric':<20} {'Value':<10}\")\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"{'Overall Accuracy':<20} {accuracy:<10.4f}\")\n",
        "        print(f\"{'Weighted Precision':<20} {precision:<10.4f}\")\n",
        "        print(f\"{'Weighted Recall':<20} {recall:<10.4f}\")\n",
        "        print(f\"{'Weighted F1-Score':<20} {f1:<10.4f}\")\n",
        "        print(f\"{'Total Samples':<20} {len(all_labels_np):<10}\")\n",
        "\n",
        "        print(f\"\\n🏆 CLASS-WISE PERFORMANCE:\")\n",
        "        print(f\"{'Class':<12} {'Accuracy':<10} {'Support':<8}\")\n",
        "        print(\"-\" * 30)\n",
        "        for class_name in self.class_names:\n",
        "            print(f\"{class_name:<12} {class_accuracy[class_name]:<10.4f} {class_support[class_name]:<8}\")\n",
        "\n",
        "        # FIXED: Use the imported classification_report function\n",
        "        print(f\"\\n📋 DETAILED CLASSIFICATION REPORT:\")\n",
        "        detailed_report = classification_report(all_labels_np, all_preds_np, target_names=self.class_names, zero_division=0)\n",
        "        print(detailed_report)\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs('classification_validation', exist_ok=True)\n",
        "\n",
        "        # 1. Confusion Matrix\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.class_names,\n",
        "                   yticklabels=self.class_names,\n",
        "                   annot_kws={'size': 12})\n",
        "        plt.title('Classification Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "        plt.ylabel('True Label', fontsize=12)\n",
        "        plt.xlabel('Predicted Label', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('classification_validation/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # 2. Class-wise Accuracy Bar Plot\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        class_acc_values = [class_accuracy[name] for name in self.class_names]\n",
        "        bars = plt.bar(self.class_names, class_acc_values,\n",
        "                      color=['#ff6b6b', '#4ecdc4', '#45b7d1'], alpha=0.8, edgecolor='black')\n",
        "        plt.title('Class-wise Classification Accuracy', fontsize=16, fontweight='bold')\n",
        "        plt.ylabel('Accuracy', fontsize=12)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, acc in zip(bars, class_acc_values):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('classification_validation/class_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # 3. Precision-Recall-F1 Plot\n",
        "        metrics_data = {\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1-Score': f1\n",
        "        }\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(list(metrics_data.keys()), list(metrics_data.values()),\n",
        "                      color=['#ff9f43', '#48cae4', '#06d6a0'], alpha=0.8, edgecolor='black')\n",
        "        plt.title('Classification Metrics Overview', fontsize=16, fontweight='bold')\n",
        "        plt.ylabel('Score', fontsize=12)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar, val in zip(bars, list(metrics_data.values())):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                    f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('classification_validation/metrics_overview.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # ====================================================\n",
        "        # JSON REPORT (RENAMED TO AVOID CONFLICT)\n",
        "        # ====================================================\n",
        "        classification_results_report = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'model_info': {\n",
        "                'architecture': 'ConvNeXt-Base',\n",
        "                'num_classes': len(self.class_names),\n",
        "                'classes': self.class_names\n",
        "            },\n",
        "            'dataset_info': {\n",
        "                'test_samples': len(all_labels_np),\n",
        "                'class_distribution': {name: int(support) for name, support in class_support.items()}\n",
        "            },\n",
        "            'metrics': {\n",
        "                'accuracy': float(accuracy),\n",
        "                'precision_weighted': float(precision),\n",
        "                'recall_weighted': float(recall),\n",
        "                'f1_weighted': float(f1),\n",
        "                'confusion_matrix': cm.tolist()\n",
        "            },\n",
        "            'class_metrics': {\n",
        "                name: {\n",
        "                    'accuracy': float(class_accuracy[name]),\n",
        "                    'support': int(class_support[name])\n",
        "                } for name in self.class_names\n",
        "            },\n",
        "            'detailed_report': detailed_report  # Store the string report\n",
        "        }\n",
        "\n",
        "        report_filename = f'classification_validation/classification_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
        "        with open(report_filename, 'w') as f:\n",
        "            json.dump(classification_results_report, f, indent=2)\n",
        "\n",
        "        print(f\"\\n📄 Classification report saved: {report_filename}\")\n",
        "\n",
        "        # ====================================================\n",
        "        # FINAL SUMMARY\n",
        "        # ====================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🎯 CLASSIFICATION VALIDATION SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"🏆 Overall Performance:\")\n",
        "        print(f\"   📊 Accuracy:     {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
        "        print(f\"   📈 F1-Score:     {f1:.4f}\")\n",
        "        print(f\"   ⚖️  Precision:   {precision:.4f}\")\n",
        "        print(f\"   🔄 Recall:       {recall:.4f}\")\n",
        "        print(f\"   📦 Total Samples: {len(all_labels_np)}\")\n",
        "\n",
        "        print(f\"\\n🏷️  Class Performance:\")\n",
        "        for class_name in self.class_names:\n",
        "            print(f\"   {class_name:<12}: {class_accuracy[class_name]:.4f} ({class_support[class_name]} samples)\")\n",
        "\n",
        "        print(f\"\\n📁 Generated Files:\")\n",
        "        print(f\"   📊 {report_filename}\")\n",
        "        print(f\"   📈 classification_validation/confusion_matrix.png\")\n",
        "        print(f\"   📈 classification_validation/class_accuracy.png\")\n",
        "        print(f\"   📈 classification_validation/metrics_overview.png\")\n",
        "\n",
        "        # Performance assessment\n",
        "        if accuracy > 0.90:\n",
        "            print(f\"\\n🎉 EXCELLENT PERFORMANCE! Model is ready for deployment.\")\n",
        "        elif accuracy > 0.80:\n",
        "            print(f\"\\n👍 GOOD PERFORMANCE! Model is suitable for research/clinical validation.\")\n",
        "        else:\n",
        "            print(f\"\\n⚠️  CONSIDER IMPROVEMENT: Accuracy {accuracy:.1%} may need additional training.\")\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'confusion_matrix': cm,\n",
        "            'class_accuracy': class_accuracy,\n",
        "            'class_support': class_support,\n",
        "            'predictions': all_preds_np,\n",
        "            'labels': all_labels_np,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'total_samples': len(all_labels_np),\n",
        "            'report': classification_results_report\n",
        "        }\n",
        "\n",
        "# ====================================================\n",
        "# MAIN EXECUTION - CLASSIFICATION\n",
        "# ====================================================\n",
        "\n",
        "def run_classification_validation():\n",
        "    \"\"\"Run complete classification validation\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🚀 CLASSIFICATION MODEL VALIDATION PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Check if model exists\n",
        "    if not os.path.exists(config.MODEL_PATH):\n",
        "        print(f\"❌ Model file not found: {config.MODEL_PATH}\")\n",
        "        print(\"Please train the classification model first.\")\n",
        "        return None\n",
        "\n",
        "    # Initialize and run validation\n",
        "    validator = ClassificationValidator(config.MODEL_PATH, config.CLASSES)\n",
        "    results = validator.validate()\n",
        "\n",
        "    if results:\n",
        "        print(f\"\\n🎉 CLASSIFICATION VALIDATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"✅ Model performance: {results['accuracy']*100:.1f}% accuracy\")\n",
        "        return results\n",
        "    else:\n",
        "        print(f\"\\n❌ Classification validation failed.\")\n",
        "        return None\n",
        "\n",
        "# Run classification validation\n",
        "if __name__ == \"__main__\":\n",
        "    classification_results = run_classification_validation()"
      ],
      "metadata": {
        "id": "86KphWx944qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **validation code for the segmentation**"
      ],
      "metadata": {
        "id": "EkuZbqjK4756"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install segmentation-models-pytorch albumentations scikit-image matplotlib seaborn -q\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from skimage import measure\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from glob import glob\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ====================================================\n",
        "# SEGMENTATION CONFIGURATION\n",
        "# ====================================================\n",
        "\n",
        "class SegmentationConfig:\n",
        "    BASE_DIR = '/content/dataset/Brain_Stroke_CT_Dataset'\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    NUM_WORKERS = 2\n",
        "    IMG_HEIGHT = 256\n",
        "    IMG_WIDTH = 256\n",
        "    BATCH_SIZE = 4  # Smaller for detailed analysis\n",
        "    MODEL_PATH = 'best_stroke_segmentation_model.pth'\n",
        "    SEGMENTATION_THRESHOLD = 0.5  # Binary segmentation threshold for pixels\n",
        "    STROKE_DETECTION_THRESHOLD = 0.01  # 1% threshold for image-level stroke detection (OPTIMIZED!)\n",
        "\n",
        "config = SegmentationConfig()\n",
        "print(f\"🔧 Segmentation validation - Using device: {config.DEVICE}\")\n",
        "print(f\"🎯 Default stroke detection threshold: {config.STROKE_DETECTION_THRESHOLD:.0%} (OPTIMIZED!)\")\n",
        "\n",
        "# Function to extract red mask from OVERLAY\n",
        "def extract_red_mask_from_path(mask_path, width=256, height=256):\n",
        "    if mask_path is None or not os.path.exists(mask_path):\n",
        "        return np.zeros((height, width), dtype=np.float32)\n",
        "    overlay = cv2.imread(mask_path)\n",
        "    if overlay is None:\n",
        "        return np.zeros((height, width), dtype=np.float32)\n",
        "    hsv = cv2.cvtColor(overlay, cv2.COLOR_BGR2HSV)\n",
        "    lower1, upper1 = np.array([0, 50, 50]), np.array([10, 255, 255])\n",
        "    lower2, upper2 = np.array([170, 50, 50]), np.array([180, 255, 255])\n",
        "    mask = cv2.inRange(hsv, lower1, upper1) | cv2.inRange(hsv, lower2, upper2)\n",
        "    mask = (mask > 0).astype(np.float32)\n",
        "    mask = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "    return mask\n",
        "\n",
        "# Load segmentation data\n",
        "def load_segmentation_data(base_dir, split):\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "    classes = ['Bleeding', 'Ischemia', 'Normal']\n",
        "\n",
        "    for cls in classes:\n",
        "        png_dir = os.path.join(base_dir, split, 'PNG', cls)\n",
        "        overlay_dir = os.path.join(base_dir, split, 'OVERLAY', cls)\n",
        "\n",
        "        if not os.path.exists(png_dir):\n",
        "            print(f\"PNG folder not found for {cls} in {split}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        png_files = glob(os.path.join(png_dir, '*.png'))\n",
        "        print(f\"Found {len(png_files)} images for class {cls} in {split}\")\n",
        "\n",
        "        for png in png_files:\n",
        "            filename = os.path.basename(png)\n",
        "            overlay = os.path.join(overlay_dir, filename)\n",
        "            image_paths.append(png)\n",
        "            mask_paths.append(overlay if os.path.exists(overlay) else None)\n",
        "\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Load test data\n",
        "print(\"🔍 Loading segmentation test data...\")\n",
        "test_images, test_masks = load_segmentation_data(config.BASE_DIR, 'test')\n",
        "print(f\"✅ Segmentation test samples: {len(test_images)}\")\n",
        "\n",
        "# ====================================================\n",
        "# SEGMENTATION DATASET\n",
        "# ====================================================\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transforms=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transforms = transforms\n",
        "        print(f\"📊 Segmentation dataset initialized with {len(image_paths)} samples\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img = cv2.imread(self.image_paths[idx])\n",
        "        if img is None:\n",
        "            img = np.zeros((config.IMG_HEIGHT, config.IMG_WIDTH, 3), dtype=np.uint8)\n",
        "            print(f\"⚠️  Warning: Could not load image {self.image_paths[idx]}\")\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (config.IMG_WIDTH, config.IMG_HEIGHT))\n",
        "\n",
        "        # Load mask\n",
        "        msk = extract_red_mask_from_path(self.mask_paths[idx], config.IMG_WIDTH, config.IMG_HEIGHT)\n",
        "\n",
        "        # Ensure mask has correct shape\n",
        "        if len(msk.shape) != 2:\n",
        "            msk = msk.squeeze()\n",
        "        if msk.shape != (config.IMG_HEIGHT, config.IMG_WIDTH):\n",
        "            msk = cv2.resize(msk, (config.IMG_WIDTH, config.IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
        "            msk = msk.astype(np.float32)\n",
        "\n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image=img, mask=msk)\n",
        "            img, msk = transformed['image'], transformed['mask']\n",
        "\n",
        "            # Ensure mask has channel dimension (1, H, W)\n",
        "            if len(msk.shape) == 2:\n",
        "                msk = msk.unsqueeze(0)\n",
        "\n",
        "        return img, msk\n",
        "\n",
        "# Validation transforms\n",
        "val_transforms = A.Compose([\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Create test dataset and loader\n",
        "test_dataset = SegmentationDataset(test_images, test_masks, val_transforms)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"✅ Segmentation test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "# ====================================================\n",
        "# SEGMENTATION MODEL VALIDATOR\n",
        "# ====================================================\n",
        "\n",
        "class SegmentationValidator:\n",
        "    def __init__(self, model_path):\n",
        "        \"\"\"Initialize segmentation validator\"\"\"\n",
        "        self.device = config.DEVICE\n",
        "\n",
        "        # Load model\n",
        "        self.model = smp.Unet(\n",
        "            encoder_name='efficientnet-b4',\n",
        "            encoder_weights=None,\n",
        "            in_channels=3,\n",
        "            classes=1,\n",
        "            activation=None,\n",
        "        ).to(self.device)\n",
        "\n",
        "        if os.path.exists(model_path):\n",
        "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "            print(f\"✅ Segmentation model loaded from {model_path}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"❌ Segmentation model not found: {model_path}\")\n",
        "\n",
        "        self.model.eval()\n",
        "        print(f\"🔧 Segmentation validator initialized on {self.device}\")\n",
        "        print(f\"🎯 Using {config.STROKE_DETECTION_THRESHOLD:.0%} default threshold for stroke detection\")\n",
        "\n",
        "    def calculate_detailed_metrics(self, pred_prob, true_mask, threshold=config.SEGMENTATION_THRESHOLD):\n",
        "        \"\"\"Calculate comprehensive segmentation metrics\"\"\"\n",
        "        # Ensure both are numpy arrays\n",
        "        if isinstance(pred_prob, torch.Tensor):\n",
        "            pred_prob = pred_prob.cpu().numpy()\n",
        "        if isinstance(true_mask, torch.Tensor):\n",
        "            true_mask = true_mask.cpu().numpy()\n",
        "\n",
        "        # Remove channel dimension if present\n",
        "        if len(pred_prob.shape) == 3:\n",
        "            pred_prob = pred_prob.squeeze(0)\n",
        "        if len(true_mask.shape) == 3:\n",
        "            true_mask = true_mask.squeeze(0)\n",
        "\n",
        "        # Ensure same shape\n",
        "        if pred_prob.shape != true_mask.shape:\n",
        "            min_h = min(pred_prob.shape[0], true_mask.shape[0])\n",
        "            min_w = min(pred_prob.shape[1], true_mask.shape[1])\n",
        "            pred_prob = pred_prob[:min_h, :min_w]\n",
        "            true_mask = true_mask[:min_h, :min_w]\n",
        "\n",
        "        pred_binary = (pred_prob > threshold).astype(np.uint8)\n",
        "        true_binary = (true_mask > threshold).astype(np.uint8)\n",
        "\n",
        "        # Flatten for pixel-wise metrics\n",
        "        pred_flat = pred_binary.flatten()\n",
        "        true_flat = true_binary.flatten()\n",
        "\n",
        "        # Check shapes match\n",
        "        if pred_flat.shape != true_flat.shape:\n",
        "            print(f\"⚠️  Shape mismatch in metrics: pred={pred_flat.shape}, true={true_flat.shape}\")\n",
        "            return {\n",
        "                'dice': 0.0, 'iou': 0.0, 'precision': 0.0, 'recall': 0.0,\n",
        "                'sensitivity': 0.0, 'specificity': 0.0, 'accuracy': 0.0, 'f1': 0.0,\n",
        "                'tp': 0, 'fp': 0, 'fn': 0, 'tn': 0\n",
        "            }\n",
        "\n",
        "        # Confusion matrix components\n",
        "        tp = np.sum((pred_flat == 1) & (true_flat == 1))\n",
        "        fp = np.sum((pred_flat == 1) & (true_flat == 0))\n",
        "        fn = np.sum((pred_flat == 0) & (true_flat == 1))\n",
        "        tn = np.sum((pred_flat == 0) & (true_flat == 0))\n",
        "\n",
        "        # Dice Score\n",
        "        dice = (2 * tp + 1e-7) / (2 * tp + fp + fn + 1e-7)\n",
        "\n",
        "        # IoU (Jaccard)\n",
        "        iou = (tp + 1e-7) / (tp + fp + fn + 1e-7)\n",
        "\n",
        "        # Precision and Recall\n",
        "        precision = (tp + 1e-7) / (tp + fp + 1e-7)\n",
        "        recall = (tp + 1e-7) / (tp + fn + 1e-7)\n",
        "\n",
        "        # Sensitivity (Recall) and Specificity\n",
        "        sensitivity = recall\n",
        "        specificity = (tn + 1e-7) / (tn + fp + 1e-7)\n",
        "\n",
        "        # Accuracy\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-7)\n",
        "\n",
        "        # F1 Score\n",
        "        f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
        "\n",
        "        return {\n",
        "            'dice': dice, 'iou': iou, 'precision': precision, 'recall': recall,\n",
        "            'sensitivity': sensitivity, 'specificity': specificity, 'accuracy': accuracy, 'f1': f1,\n",
        "            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
        "        }\n",
        "\n",
        "    def classify_stroke_presence(self, mask, threshold=config.STROKE_DETECTION_THRESHOLD):\n",
        "        \"\"\"Classify image as Normal (0) or Stroke (1) based on mask area ratio\"\"\"\n",
        "        if isinstance(mask, torch.Tensor):\n",
        "            mask = mask.cpu().numpy()\n",
        "\n",
        "        if len(mask.shape) == 3:\n",
        "            mask = mask.squeeze(0)\n",
        "\n",
        "        mask_flat = mask.flatten()\n",
        "        stroke_pixels = np.sum(mask_flat > config.SEGMENTATION_THRESHOLD)\n",
        "        total_pixels = len(mask_flat)\n",
        "        stroke_ratio = stroke_pixels / total_pixels\n",
        "\n",
        "        return 1 if stroke_ratio > threshold else 0, stroke_ratio\n",
        "\n",
        "    def analyze_stroke_distribution(self, true_masks, pred_masks):\n",
        "        \"\"\"Analyze stroke area distribution for diagnostics\"\"\"\n",
        "        print(\"\\n🔍 STROKE AREA DISTRIBUTION ANALYSIS:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        true_stroke_ratios = []\n",
        "        pred_stroke_ratios = []\n",
        "\n",
        "        for true_mask, pred_mask in zip(true_masks, pred_masks):\n",
        "            true_class, true_ratio = self.classify_stroke_presence(true_mask)\n",
        "            true_stroke_ratios.append(true_ratio)\n",
        "\n",
        "            pred_class, pred_ratio = self.classify_stroke_presence(pred_mask)\n",
        "            pred_stroke_ratios.append(pred_ratio)\n",
        "\n",
        "        # Statistics\n",
        "        true_stroke_cases = sum(1 for r in true_stroke_ratios if r >= config.STROKE_DETECTION_THRESHOLD)\n",
        "        pred_stroke_cases = sum(1 for r in pred_stroke_ratios if r >= config.STROKE_DETECTION_THRESHOLD)\n",
        "\n",
        "        print(f\"True Stroke Cases (≥{config.STROKE_DETECTION_THRESHOLD:.0%} area):  {true_stroke_cases:>4}/{len(true_stroke_ratios)} ({true_stroke_cases/len(true_stroke_ratios)*100:.1f}%)\")\n",
        "        print(f\"Predicted Stroke Cases (≥{config.STROKE_DETECTION_THRESHOLD:.0%}): {pred_stroke_cases:>4}/{len(pred_stroke_ratios)} ({pred_stroke_cases/len(pred_stroke_ratios)*100:.1f}%)\")\n",
        "\n",
        "        print(f\"\\nTrue Stroke Area - Mean: {np.mean(true_stroke_ratios):.4f}, Median: {np.median(true_stroke_ratios):.4f}\")\n",
        "        print(f\"Predicted Stroke Area - Mean: {np.mean(pred_stroke_ratios):.4f}, Median: {np.median(pred_stroke_ratios):.4f}\")\n",
        "\n",
        "        # Threshold analysis\n",
        "        print(f\"\\n🎯 THRESHOLD SENSITIVITY ANALYSIS:\")\n",
        "        print(f\"{'Threshold':<10} {'True Pos':<8} {'Pred Pos':<8} {'Accuracy':<8} {'F1':<8}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        thresholds = [0.01, 0.02, 0.05, 0.10, 0.15, 0.20]\n",
        "        threshold_results = {}\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            true_pos = sum(1 for r in true_stroke_ratios if r >= threshold)\n",
        "            pred_pos = sum(1 for r in pred_stroke_ratios if r >= threshold)\n",
        "\n",
        "            true_classes = [1 if r >= threshold else 0 for r in true_stroke_ratios]\n",
        "            pred_classes = [1 if r >= threshold else 0 for r in pred_stroke_ratios]\n",
        "\n",
        "            acc = accuracy_score(true_classes, pred_classes)\n",
        "            f1_score_val = f1_score(true_classes, pred_classes, zero_division=0)\n",
        "\n",
        "            threshold_results[threshold] = {'accuracy': acc, 'f1': f1_score_val}\n",
        "            print(f\"{threshold:<10.2f} {true_pos:<8} {pred_pos:<8} {acc:<8.3f} {f1_score_val:<8.3f}\")\n",
        "\n",
        "        # Find optimal threshold\n",
        "        best_threshold = max(thresholds, key=lambda k: threshold_results[k]['f1'])\n",
        "        best_f1 = threshold_results[best_threshold]['f1']\n",
        "        print(f\"\\n🎯 OPTIMAL THRESHOLD: {best_threshold} (F1 = {best_f1:.3f})\")\n",
        "\n",
        "        return threshold_results, best_threshold, true_stroke_ratios, pred_stroke_ratios\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Run comprehensive segmentation validation\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🔬 SEGMENTATION MODEL VALIDATION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        all_metrics = []\n",
        "        all_true_masks = []\n",
        "        all_pred_masks = []\n",
        "        all_true_classes = []\n",
        "        all_pred_classes = []\n",
        "        valid_samples = 0\n",
        "        error_count = 0\n",
        "\n",
        "        print(f\"📊 Processing {len(test_dataset)} test samples...\")\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm(test_loader, desc=\"Validating\", unit=\"batch\")\n",
        "            for batch_idx, (images, masks) in enumerate(progress_bar):\n",
        "                images = images.to(self.device)\n",
        "\n",
        "                # Ensure masks have proper shape\n",
        "                if masks.dim() == 3:\n",
        "                    masks = masks.unsqueeze(1)\n",
        "                masks = masks.to(self.device)\n",
        "\n",
        "                # Get predictions\n",
        "                logits = self.model(images)\n",
        "                probs = torch.sigmoid(logits)\n",
        "\n",
        "                # Process each sample in batch\n",
        "                for i in range(images.shape[0]):\n",
        "                    try:\n",
        "                        pred_prob = probs[i, 0]  # Shape: (H, W)\n",
        "                        true_mask = masks[i, 0]  # Shape: (H, W)\n",
        "\n",
        "                        # Store for diagnostics\n",
        "                        all_true_masks.append(true_mask.clone())\n",
        "                        all_pred_masks.append(pred_prob.clone())\n",
        "\n",
        "                        # Only process samples with meaningful content\n",
        "                        if torch.sum(true_mask) > 0 or torch.sum(pred_prob > config.SEGMENTATION_THRESHOLD) > 0:\n",
        "                            metrics = self.calculate_detailed_metrics(pred_prob, true_mask)\n",
        "                            all_metrics.append(metrics)\n",
        "                            valid_samples += 1\n",
        "\n",
        "                            # Classify stroke presence (default 1% threshold)\n",
        "                            true_class, _ = self.classify_stroke_presence(true_mask)\n",
        "                            pred_class, _ = self.classify_stroke_presence(pred_prob)\n",
        "\n",
        "                            all_true_classes.append(true_class)\n",
        "                            all_pred_classes.append(pred_class)\n",
        "\n",
        "                        # Progress update\n",
        "                        if valid_samples % 50 == 0 and all_metrics:\n",
        "                            avg_dice = np.mean([m['dice'] for m in all_metrics[-50:]])\n",
        "                            progress_bar.set_postfix({\n",
        "                                'Dice': f\"{avg_dice:.3f}\",\n",
        "                                'Samples': valid_samples\n",
        "                            })\n",
        "                    except Exception as e:\n",
        "                        error_count += 1\n",
        "                        print(f\"⚠️  Error processing sample {i} in batch {batch_idx}: {e}\")\n",
        "                        continue\n",
        "\n",
        "        print(f\"\\n✅ Validation complete! Processed {valid_samples} valid samples\")\n",
        "        if error_count > 0:\n",
        "            print(f\"⚠️  Encountered {error_count} errors during processing\")\n",
        "\n",
        "        # Calculate classification metrics (default 1% threshold)\n",
        "        if all_true_classes:\n",
        "            default_accuracy = accuracy_score(all_true_classes, all_pred_classes)\n",
        "            default_precision = precision_score(all_true_classes, all_pred_classes, zero_division=0)\n",
        "            default_recall = recall_score(all_true_classes, all_pred_classes, zero_division=0)\n",
        "            default_f1 = f1_score(all_true_classes, all_pred_classes, zero_division=0)\n",
        "            default_cm = confusion_matrix(all_true_classes, all_pred_classes)\n",
        "        else:\n",
        "            default_accuracy = default_precision = default_recall = default_f1 = 0.0\n",
        "            default_cm = np.zeros((2, 2))\n",
        "\n",
        "        # Calculate segmentation statistics\n",
        "        if all_metrics:\n",
        "            dice_scores = [m['dice'] for m in all_metrics]\n",
        "            iou_scores = [m['iou'] for m in all_metrics]\n",
        "            precision_scores = [m['precision'] for m in all_metrics]\n",
        "            recall_scores = [m['recall'] for m in all_metrics]\n",
        "            sensitivity_scores = [m['sensitivity'] for m in all_metrics]\n",
        "            specificity_scores = [m['specificity'] for m in all_metrics]\n",
        "            f1_scores = [m['f1'] for m in all_metrics]\n",
        "            accuracy_scores = [m['accuracy'] for m in all_metrics]\n",
        "        else:\n",
        "            dice_scores = iou_scores = precision_scores = recall_scores = []\n",
        "            sensitivity_scores = specificity_scores = f1_scores = accuracy_scores = []\n",
        "\n",
        "        # ====================================================\n",
        "        # PRINT SEGMENTATION RESULTS TABLE\n",
        "        # ====================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📊 SEGMENTATION PERFORMANCE METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"{'Metric':<15} {'Mean':<10} {'Std':<10} {'Best':<10} {'Worst':<10}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        metrics_table = [\n",
        "            ('Dice Score', dice_scores),\n",
        "            ('IoU Score', iou_scores),\n",
        "            ('Precision', precision_scores),\n",
        "            ('Recall', recall_scores),\n",
        "            ('Sensitivity', sensitivity_scores),\n",
        "            ('Specificity', specificity_scores),\n",
        "            ('F1 Score', f1_scores),\n",
        "            ('Accuracy', accuracy_scores)\n",
        "        ]\n",
        "\n",
        "        for metric_name, scores in metrics_table:\n",
        "            if scores:\n",
        "                mean_val = np.mean(scores)\n",
        "                std_val = np.std(scores)\n",
        "                best_val = np.max(scores)\n",
        "                worst_val = np.min(scores)\n",
        "                print(f\"{metric_name:<15} {mean_val:<10.4f} {std_val:<10.4f} {best_val:<10.4f} {worst_val:<10.4f}\")\n",
        "            else:\n",
        "                print(f\"{metric_name:<15} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10}\")\n",
        "\n",
        "        # ====================================================\n",
        "        # STROKE DETECTION RESULTS (DEFAULT 1% THRESHOLD)\n",
        "        # ====================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"🏥 STROKE DETECTION CLASSIFICATION ({config.STROKE_DETECTION_THRESHOLD:.0%} Threshold)\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"{'Metric':<15} {'Value':<10}\")\n",
        "        print(\"-\" * 25)\n",
        "        print(f\"{'Accuracy':<15} {default_accuracy:<10.4f}\")\n",
        "        print(f\"{'Precision':<15} {default_precision:<10.4f}\")\n",
        "        print(f\"{'Recall':<15} {default_recall:<10.4f}\")\n",
        "        print(f\"{'F1-Score':<15} {default_f1:<10.4f}\")\n",
        "        print(f\"{'Stroke Cases':<15} {sum(all_true_classes):<10}/{valid_samples}\")\n",
        "\n",
        "        print(f\"\\n📊 Confusion Matrix (Normal/Stroke):\")\n",
        "        print(f\"                  Predicted\")\n",
        "        print(f\"              Normal  Stroke\")\n",
        "        print(f\"True Normal   {default_cm[0,0]:^7}  {default_cm[0,1]:^7}\")\n",
        "        print(f\"True Stroke   {default_cm[1,0]:^7}  {default_cm[1,1]:^7}\")\n",
        "\n",
        "        # ====================================================\n",
        "        # STROKE DISTRIBUTION DIAGNOSTICS\n",
        "        # ====================================================\n",
        "        print(\"\\n🔍 RUNNING STROKE DISTRIBUTION ANALYSIS...\")\n",
        "        threshold_results, best_threshold, true_stroke_ratios, pred_stroke_ratios = self.analyze_stroke_distribution(\n",
        "            all_true_masks, all_pred_masks\n",
        "        )\n",
        "\n",
        "        # Recalculate with optimal threshold\n",
        "        optimal_true_classes = [1 if self.classify_stroke_presence(mask, best_threshold)[1] >= best_threshold else 0\n",
        "                               for mask in all_true_masks]\n",
        "        optimal_pred_classes = [1 if self.classify_stroke_presence(mask, best_threshold)[1] >= best_threshold else 0\n",
        "                               for mask in all_pred_masks]\n",
        "\n",
        "        optimal_accuracy = accuracy_score(optimal_true_classes, optimal_pred_classes)\n",
        "        optimal_f1 = f1_score(optimal_true_classes, optimal_pred_classes, zero_division=0)\n",
        "        optimal_cm = confusion_matrix(optimal_true_classes, optimal_pred_classes)\n",
        "\n",
        "        print(f\"\\n🎯 OPTIMAL PERFORMANCE (Threshold = {best_threshold:.0%}):\")\n",
        "        print(f\"   Accuracy: {optimal_accuracy:.4f} | F1-Score: {optimal_f1:.4f}\")\n",
        "\n",
        "        # ====================================================\n",
        "        # VISUALIZATIONS\n",
        "        # ====================================================\n",
        "        print(\"\\n📈 Generating visualizations...\")\n",
        "        os.makedirs('segmentation_validation', exist_ok=True)\n",
        "\n",
        "        # 1. Sample Predictions Visualization\n",
        "        stroke_samples = []\n",
        "        for i in range(min(50, len(test_images))):\n",
        "            try:\n",
        "                mask = extract_red_mask_from_path(test_masks[i], config.IMG_WIDTH, config.IMG_HEIGHT)\n",
        "                if np.sum(mask) > 100:  # At least 100 stroke pixels\n",
        "                    stroke_samples.append(i)\n",
        "                    if len(stroke_samples) >= 4:\n",
        "                        break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if stroke_samples:\n",
        "            fig, axes = plt.subplots(4, len(stroke_samples), figsize=(5*len(stroke_samples), 20))\n",
        "            if len(stroke_samples) == 1:\n",
        "                axes = axes.reshape(-1, 1)\n",
        "\n",
        "            fig.suptitle(f'SEGMENTATION: Sample Predictions (Stroke Cases)', fontsize=16)\n",
        "\n",
        "            for idx, sample_idx in enumerate(stroke_samples):\n",
        "                try:\n",
        "                    # Load image\n",
        "                    img = cv2.imread(test_images[sample_idx])\n",
        "                    if img is None:\n",
        "                        continue\n",
        "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img_resized = cv2.resize(img_rgb, (config.IMG_WIDTH, config.IMG_HEIGHT))\n",
        "\n",
        "                    # Get prediction\n",
        "                    transformed = val_transforms(image=img_resized, mask=np.zeros((config.IMG_HEIGHT, config.IMG_WIDTH), dtype=np.float32))\n",
        "                    img_tensor = transformed['image'].unsqueeze(0).to(self.device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        pred_logits = self.model(img_tensor)\n",
        "                        pred_prob = torch.sigmoid(pred_logits)[0, 0].cpu().numpy()\n",
        "                        pred_mask = (pred_prob > config.SEGMENTATION_THRESHOLD).astype(np.uint8) * 255\n",
        "\n",
        "                    true_mask = extract_red_mask_from_path(test_masks[sample_idx], config.IMG_WIDTH, config.IMG_HEIGHT)\n",
        "                    sample_metrics = self.calculate_detailed_metrics(pred_prob, true_mask)\n",
        "\n",
        "                    # Stroke ratios\n",
        "                    true_stroke_ratio = np.sum(true_mask > 0) / (config.IMG_HEIGHT * config.IMG_WIDTH)\n",
        "                    pred_stroke_ratio = np.sum(pred_prob > config.SEGMENTATION_THRESHOLD) / (config.IMG_HEIGHT * config.IMG_WIDTH)\n",
        "\n",
        "                    # Optimal classification\n",
        "                    true_class_opt = 1 if true_stroke_ratio >= best_threshold else 0\n",
        "                    pred_class_opt = 1 if pred_stroke_ratio >= best_threshold else 0\n",
        "\n",
        "                    # Plot\n",
        "                    axes[0, idx].imshow(img_resized)\n",
        "                    axes[0, idx].set_title(f'Original #{idx+1}\\nTrue:{true_class_opt} Pred:{pred_class_opt}', fontsize=10)\n",
        "                    axes[0, idx].axis('off')\n",
        "\n",
        "                    axes[1, idx].imshow(true_mask, cmap='Reds')\n",
        "                    axes[1, idx].set_title(f'True Mask\\nArea: {true_stroke_ratio:.1%}', fontsize=10)\n",
        "                    axes[1, idx].axis('off')\n",
        "\n",
        "                    axes[2, idx].imshow(pred_mask, cmap='Blues')\n",
        "                    axes[2, idx].set_title(f'Pred Mask (T={config.SEGMENTATION_THRESHOLD})\\nDice: {sample_metrics[\"dice\"]:.3f}', fontsize=10)\n",
        "                    axes[2, idx].axis('off')\n",
        "\n",
        "                    # Overlay\n",
        "                    overlay = img_resized.copy()\n",
        "                    overlay[pred_mask > 0] = [255, 0, 0]  # Red for prediction\n",
        "                    overlay[true_mask > 0] = [0, 255, 0]  # Green for ground truth\n",
        "                    axes[3, idx].imshow(overlay)\n",
        "                    axes[3, idx].set_title(f'Overlay Comparison\\nIoU: {sample_metrics[\"iou\"]:.3f}', fontsize=10)\n",
        "                    axes[3, idx].axis('off')\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in visualization for sample {sample_idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('segmentation_validation/sample_predictions.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "        # 2. Metrics Distribution\n",
        "        if len(dice_scores) > 1:\n",
        "            fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "            fig.suptitle('Segmentation Metrics Distribution', fontsize=16)\n",
        "\n",
        "            metrics_data = [\n",
        "                ('Dice Score', dice_scores, 'Dice'),\n",
        "                ('IoU Score', iou_scores, 'IoU'),\n",
        "                ('Precision', precision_scores, 'Precision'),\n",
        "                ('Recall', recall_scores, 'Recall'),\n",
        "                ('Sensitivity', sensitivity_scores, 'Sensitivity'),\n",
        "                ('Specificity', specificity_scores, 'Specificity'),\n",
        "                ('F1 Score', f1_scores, 'F1'),\n",
        "                ('Accuracy', accuracy_scores, 'Accuracy')\n",
        "            ]\n",
        "\n",
        "            for idx, (name, scores, short_name) in enumerate(metrics_data):\n",
        "                if scores:\n",
        "                    row, col = idx // 4, idx % 4\n",
        "                    axes[row, col].hist(scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "                    axes[row, col].axvline(np.mean(scores), color='red', linestyle='--', linewidth=2,\n",
        "                                         label=f'Mean: {np.mean(scores):.3f}')\n",
        "                    axes[row, col].set_title(f'{name} Distribution')\n",
        "                    axes[row, col].set_xlabel(short_name)\n",
        "                    axes[row, col].set_ylabel('Frequency')\n",
        "                    axes[row, col].legend()\n",
        "                    axes[row, col].grid(True, alpha=0.3)\n",
        "                else:\n",
        "                    axes[row, col].text(0.5, 0.5, 'No Data', ha='center', va='center', transform=axes[row, col].transAxes)\n",
        "                    axes[row, col].set_title(f'{name} Distribution')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('segmentation_validation/metrics_distribution.png', dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "        # 3. Stroke Detection Confusion Matrix (Default vs Optimal)\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "        # Default threshold confusion matrix\n",
        "        sns.heatmap(default_cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['Normal', 'Stroke'],\n",
        "                   yticklabels=['Normal', 'Stroke'],\n",
        "                   ax=ax1, annot_kws={'size': 14})\n",
        "        ax1.set_title(f'Stroke Detection CM\\n(Default {config.STROKE_DETECTION_THRESHOLD:.0%} Threshold)\\nAcc: {default_accuracy:.3f}', fontsize=12)\n",
        "\n",
        "        # Optimal threshold confusion matrix\n",
        "        sns.heatmap(optimal_cm, annot=True, fmt='d', cmap='Greens',\n",
        "                   xticklabels=['Normal', 'Stroke'],\n",
        "                   yticklabels=['Normal', 'Stroke'],\n",
        "                   ax=ax2, annot_kws={'size': 14})\n",
        "        ax2.set_title(f'Stroke Detection CM\\n(Optimal {best_threshold:.0%} Threshold)\\nAcc: {optimal_accuracy:.3f}', fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('segmentation_validation/stroke_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # 4. Threshold Performance Curve\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Stroke area distribution\n",
        "        ax1.hist(true_stroke_ratios, bins=20, alpha=0.7, color='red', label='True', density=True)\n",
        "        ax1.hist(pred_stroke_ratios, bins=20, alpha=0.7, color='blue', label='Predicted', density=True)\n",
        "        ax1.axvline(best_threshold, color='green', linestyle='--', linewidth=2,\n",
        "                   label=f'Optimal: {best_threshold:.0%}')\n",
        "        ax1.set_title('Stroke Area Ratio Distribution')\n",
        "        ax1.set_xlabel('Stroke Area Ratio')\n",
        "        ax1.set_ylabel('Density')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Threshold performance\n",
        "        thresholds = list(threshold_results.keys())\n",
        "        accuracies = [threshold_results[t]['accuracy'] for t in thresholds]\n",
        "        f1_scores = [threshold_results[t]['f1'] for t in thresholds]\n",
        "\n",
        "        ax2.plot(thresholds, accuracies, 'o-', linewidth=2, label='Accuracy', color='blue')\n",
        "        ax2.plot(thresholds, f1_scores, 's-', linewidth=2, label='F1-Score', color='red')\n",
        "        ax2.axvline(best_threshold, color='green', linestyle='--', linewidth=2,\n",
        "                   label=f'Optimal: {best_threshold:.0%}')\n",
        "        ax2.set_title('Threshold Performance Analysis')\n",
        "        ax2.set_xlabel('Stroke Area Threshold')\n",
        "        ax2.set_ylabel('Score')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.set_ylim(0, 1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('segmentation_validation/threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # ====================================================\n",
        "        # COMPREHENSIVE JSON REPORT\n",
        "        # ====================================================\n",
        "        segmentation_report = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'model_info': {\n",
        "                'architecture': 'U-Net',\n",
        "                'encoder': 'efficientnet-b4',\n",
        "                'input_size': f\"{config.IMG_HEIGHT}x{config.IMG_WIDTH}\",\n",
        "                'segmentation_threshold': float(config.SEGMENTATION_THRESHOLD),\n",
        "                'stroke_detection_threshold': float(config.STROKE_DETECTION_THRESHOLD)\n",
        "            },\n",
        "            'dataset_info': {\n",
        "                'total_samples': len(test_dataset),\n",
        "                'valid_samples': valid_samples,\n",
        "                'error_count': error_count\n",
        "            },\n",
        "            'segmentation_metrics': {\n",
        "                'dice': {\n",
        "                    'mean': float(np.mean(dice_scores)) if dice_scores else 0.0,\n",
        "                    'std': float(np.std(dice_scores)) if dice_scores else 0.0,\n",
        "                    'min': float(np.min(dice_scores)) if dice_scores else 0.0,\n",
        "                    'max': float(np.max(dice_scores)) if dice_scores else 0.0\n",
        "                },\n",
        "                'iou': {\n",
        "                    'mean': float(np.mean(iou_scores)) if iou_scores else 0.0,\n",
        "                    'std': float(np.std(iou_scores)) if iou_scores else 0.0,\n",
        "                    'min': float(np.min(iou_scores)) if iou_scores else 0.0,\n",
        "                    'max': float(np.max(iou_scores)) if iou_scores else 0.0\n",
        "                },\n",
        "                'precision': {\n",
        "                    'mean': float(np.mean(precision_scores)) if precision_scores else 0.0,\n",
        "                    'std': float(np.std(precision_scores)) if precision_scores else 0.0\n",
        "                },\n",
        "                'recall': {\n",
        "                    'mean': float(np.mean(recall_scores)) if recall_scores else 0.0,\n",
        "                    'std': float(np.std(recall_scores)) if recall_scores else 0.0\n",
        "                },\n",
        "                'sensitivity': {\n",
        "                    'mean': float(np.mean(sensitivity_scores)) if sensitivity_scores else 0.0,\n",
        "                    'std': float(np.std(sensitivity_scores)) if sensitivity_scores else 0.0\n",
        "                },\n",
        "                'specificity': {\n",
        "                    'mean': float(np.mean(specificity_scores)) if specificity_scores else 0.0,\n",
        "                    'std': float(np.std(specificity_scores)) if specificity_scores else 0.0\n",
        "                },\n",
        "                'f1': {\n",
        "                    'mean': float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "                    'std': float(np.std(f1_scores)) if f1_scores else 0.0\n",
        "                },\n",
        "                'accuracy': {\n",
        "                    'mean': float(np.mean(accuracy_scores)) if accuracy_scores else 0.0,\n",
        "                    'std': float(np.std(accuracy_scores)) if accuracy_scores else 0.0\n",
        "                }\n",
        "            },\n",
        "            'stroke_detection': {\n",
        "                'default_threshold': float(config.STROKE_DETECTION_THRESHOLD),\n",
        "                'default_accuracy': float(default_accuracy),\n",
        "                'default_f1': float(default_f1),\n",
        "                'default_confusion_matrix': default_cm.tolist(),\n",
        "                'optimal_threshold': float(best_threshold),\n",
        "                'optimal_accuracy': float(optimal_accuracy),\n",
        "                'optimal_f1': float(optimal_f1),\n",
        "                'optimal_confusion_matrix': optimal_cm.tolist(),\n",
        "                'threshold_analysis': {\n",
        "                    str(threshold): {\n",
        "                        'accuracy': float(threshold_results[threshold]['accuracy']),\n",
        "                        'f1': float(threshold_results[threshold]['f1'])\n",
        "                    } for threshold in threshold_results\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        report_filename = f'segmentation_validation/segmentation_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
        "        with open(report_filename, 'w') as f:\n",
        "            json.dump(segmentation_report, f, indent=2)\n",
        "\n",
        "        print(f\"\\n📄 Segmentation report saved: {report_filename}\")\n",
        "\n",
        "        # ====================================================\n",
        "        # FINAL SUMMARY\n",
        "        # ====================================================\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🎯 SEGMENTATION VALIDATION SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"🔬 Pixel-Level Performance:\")\n",
        "        if dice_scores:\n",
        "            print(f\"   🥇 Dice Score:     {np.mean(dice_scores):.4f} ± {np.std(dice_scores):.4f}\")\n",
        "            print(f\"   🥈 IoU Score:      {np.mean(iou_scores):.4f} ± {np.std(iou_scores):.4f}\")\n",
        "            print(f\"   ⚖️  Precision:     {np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\")\n",
        "            print(f\"   🔄 Recall:         {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n",
        "            print(f\"   📊 F1-Score:       {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
        "            print(f\"   🎯 Pixel Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n",
        "\n",
        "        print(f\"\\n🏥 Stroke Detection Performance:\")\n",
        "        print(f\"   📊 Default ({config.STROKE_DETECTION_THRESHOLD:.0%} threshold):  Accuracy = {default_accuracy:.4f}, F1 = {default_f1:.4f}\")\n",
        "        print(f\"   🎯 Optimal ({best_threshold:.0%} threshold): Accuracy = {optimal_accuracy:.4f}, F1 = {optimal_f1:.4f}\")\n",
        "        print(f\"   🔬 Valid Samples Processed: {valid_samples}/{len(test_dataset)}\")\n",
        "        print(f\"   🩺 True Stroke Cases: {sum(all_true_classes)}/{valid_samples}\")\n",
        "\n",
        "        # Performance assessment\n",
        "        if np.mean(dice_scores) > 0.80:\n",
        "            print(f\"\\n🎉 EXCELLENT SEGMENTATION QUALITY! Dice score > 0.80\")\n",
        "        elif np.mean(dice_scores) > 0.70:\n",
        "            print(f\"\\n👍 GOOD SEGMENTATION QUALITY! Dice score > 0.70\")\n",
        "        else:\n",
        "            print(f\"\\n⚠️  CONSIDER IMPROVEMENT: Dice score = {np.mean(dice_scores):.3f}\")\n",
        "\n",
        "        if optimal_accuracy > 0.90:\n",
        "            print(f\"🎉 EXCELLENT STROKE DETECTION! Use threshold {best_threshold:.0%}\")\n",
        "        elif optimal_accuracy > 0.80:\n",
        "            print(f\"👍 GOOD STROKE DETECTION! Use threshold {best_threshold:.0%}\")\n",
        "        else:\n",
        "            print(f\"⚠️  STROKE DETECTION NEEDS ATTENTION: {optimal_accuracy:.1%} accuracy\")\n",
        "\n",
        "        print(f\"\\n📁 Generated Files:\")\n",
        "        print(f\"   📄 {report_filename}\")\n",
        "        print(f\"   📈 segmentation_validation/sample_predictions.png\")\n",
        "        print(f\"   📈 segmentation_validation/metrics_distribution.png\")\n",
        "        print(f\"   📈 segmentation_validation/stroke_confusion_matrices.png\")\n",
        "        print(f\"   📈 segmentation_validation/threshold_analysis.png\")\n",
        "\n",
        "        return {\n",
        "            'dice_scores': dice_scores,\n",
        "            'iou_scores': iou_scores,\n",
        "            'precision_scores': precision_scores,\n",
        "            'recall_scores': recall_scores,\n",
        "            'sensitivity_scores': sensitivity_scores,\n",
        "            'specificity_scores': specificity_scores,\n",
        "            'f1_scores': f1_scores,\n",
        "            'accuracy_scores': accuracy_scores,\n",
        "            'default_stroke_accuracy': default_accuracy,\n",
        "            'default_stroke_f1': default_f1,\n",
        "            'optimal_stroke_accuracy': optimal_accuracy,\n",
        "            'optimal_stroke_f1': optimal_f1,\n",
        "            'optimal_threshold': best_threshold,\n",
        "            'default_confusion_matrix': default_cm,\n",
        "            'optimal_confusion_matrix': optimal_cm,\n",
        "            'valid_samples': valid_samples,\n",
        "            'total_samples': len(test_dataset),\n",
        "            'threshold_results': threshold_results,\n",
        "            'true_stroke_ratios': true_stroke_ratios,\n",
        "            'pred_stroke_ratios': pred_stroke_ratios,\n",
        "            'report': segmentation_report\n",
        "        }\n",
        "\n",
        "# ====================================================\n",
        "# MAIN EXECUTION - SEGMENTATION\n",
        "# ====================================================\n",
        "\n",
        "def run_segmentation_validation():\n",
        "    \"\"\"Run complete segmentation validation\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🚀 SEGMENTATION MODEL VALIDATION PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Check if model exists\n",
        "    if not os.path.exists(config.MODEL_PATH):\n",
        "        print(f\"❌ Model file not found: {config.MODEL_PATH}\")\n",
        "        print(\"Please train the segmentation model first.\")\n",
        "        return None\n",
        "\n",
        "    # Initialize and run validation\n",
        "    validator = SegmentationValidator(config.MODEL_PATH)\n",
        "    results = validator.validate()\n",
        "\n",
        "    if results:\n",
        "        print(f\"\\n🎉 SEGMENTATION VALIDATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"✅ Pixel Quality: Dice = {np.mean(results['dice_scores']):.3f}\")\n",
        "        print(f\"✅ Optimal Stroke Detection: {results['optimal_stroke_accuracy']*100:.1f}% accuracy\")\n",
        "        return results\n",
        "    else:\n",
        "        print(f\"\\n❌ Segmentation validation failed.\")\n",
        "        return None\n",
        "\n",
        "# Run segmentation validation\n",
        "if __name__ == \"__main__\":\n",
        "    segmentation_results = run_segmentation_validation()"
      ],
      "metadata": {
        "id": "vvl5dm675AnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Real world images testing**"
      ],
      "metadata": {
        "id": "UlXhE-rO5HZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required dependencies\n",
        "!pip install timm segmentation-models-pytorch albumentations opencv-python-headless matplotlib -q\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "import timm\n",
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ====================================================\n",
        "# CONFIGURATION\n",
        "# ====================================================\n",
        "\n",
        "class AppConfig:\n",
        "    CLASSIFICATION_MODEL_PATH = 'best_model_3class.pth'\n",
        "    SEGMENTATION_MODEL_PATH = 'best_stroke_segmentation_model.pth'\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    CLASSES = ['Bleeding', 'Ischemia', 'Normal']\n",
        "    STROKE_DETECTION_THRESHOLD = 0.01  # 1% threshold for stroke confirmation\n",
        "    SEGMENTATION_THRESHOLD = 0.5  # Pixel classification threshold\n",
        "\n",
        "config = AppConfig()\n",
        "print(f\"🔧 Device: {config.DEVICE}\")\n",
        "\n",
        "# ====================================================\n",
        "# MODEL LOADING\n",
        "# ====================================================\n",
        "\n",
        "# Load Classification Model (ConvNeXt)\n",
        "class ClassificationModel:\n",
        "    def __init__(self):\n",
        "        self.model = timm.create_model('convnext_base', pretrained=False, num_classes=3)\n",
        "        if os.path.exists(config.CLASSIFICATION_MODEL_PATH):\n",
        "            self.model.load_state_dict(torch.load(config.CLASSIFICATION_MODEL_PATH, map_location=config.DEVICE))\n",
        "            print(f\"✅ Classification model loaded\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Classification model not found: {config.CLASSIFICATION_MODEL_PATH}\")\n",
        "\n",
        "        self.model = self.model.to(config.DEVICE)\n",
        "        self.model.eval()\n",
        "\n",
        "        class GrayscaleToRGB:\n",
        "            def __call__(self, image):\n",
        "                if image.shape[0] == 1:\n",
        "                    return torch.cat([image] * 3, dim=0)\n",
        "                return image\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            GrayscaleToRGB(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def predict(self, image):\n",
        "        image_tensor = self.transform(image).unsqueeze(0).to(config.DEVICE)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(image_tensor)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            pred_idx = torch.argmax(probs, dim=1).item()\n",
        "            pred_prob = probs[0, pred_idx].item()\n",
        "        pred_class = config.CLASSES[pred_idx]\n",
        "        return pred_class, pred_prob\n",
        "\n",
        "# Load Segmentation Model (U-Net)\n",
        "class SegmentationModel:\n",
        "    def __init__(self):\n",
        "        self.model = smp.Unet(\n",
        "            encoder_name='efficientnet-b4',\n",
        "            encoder_weights=None,\n",
        "            in_channels=3,\n",
        "            classes=1,\n",
        "            activation=None,\n",
        "        ).to(config.DEVICE)\n",
        "\n",
        "        if os.path.exists(config.SEGMENTATION_MODEL_PATH):\n",
        "            self.model.load_state_dict(torch.load(config.SEGMENTATION_MODEL_PATH, map_location=config.DEVICE))\n",
        "            print(f\"✅ Segmentation model loaded\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Segmentation model not found: {config.SEGMENTATION_MODEL_PATH}\")\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        self.transform = A.Compose([\n",
        "            A.Resize(height=256, width=256),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Convert PIL to numpy for Albumentations\n",
        "        image_np = np.array(image.convert('RGB'))\n",
        "        transformed = self.transform(image=image_np)\n",
        "        image_tensor = transformed['image'].unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_logits = self.model(image_tensor)\n",
        "            pred_prob = torch.sigmoid(pred_logits)[0, 0].cpu().numpy()\n",
        "            pred_mask = (pred_prob > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "        # Calculate stroke ratio for confirmation\n",
        "        stroke_ratio = np.sum(pred_prob > config.SEGMENTATION_THRESHOLD) / (256 * 256)\n",
        "\n",
        "        return pred_mask, stroke_ratio\n",
        "\n",
        "# Initialize models\n",
        "print(\"🔍 Loading models...\")\n",
        "class_model = ClassificationModel()\n",
        "seg_model = SegmentationModel()\n",
        "\n",
        "# ====================================================\n",
        "# IMAGE PROCESSING FUNCTIONS\n",
        "# ====================================================\n",
        "\n",
        "def create_overlay(original, mask):\n",
        "    \"\"\"Create overlay image with stroke highlighted in red\"\"\"\n",
        "    original = np.array(original.convert('RGB'))\n",
        "    original = cv2.resize(original, (256, 256))\n",
        "\n",
        "    overlay = original.copy()\n",
        "    overlay[mask > 0] = [255, 0, 0]  # Red for stroke\n",
        "\n",
        "    return overlay\n",
        "\n",
        "# ====================================================\n",
        "# MAIN APPLICATION\n",
        "# ====================================================\n",
        "\n",
        "def process_ct_image():\n",
        "    \"\"\"Main function for processing uploaded CT image\"\"\"\n",
        "    print(\"📤 Please upload a brain CT image (PNG/JPG)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"❌ No image uploaded. Please try again.\")\n",
        "        return\n",
        "\n",
        "    # Get the uploaded image\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    image_bytes = uploaded[file_name]\n",
        "\n",
        "    # Open image\n",
        "    try:\n",
        "        image = Image.open(BytesIO(image_bytes)).convert('L')  # Convert to grayscale\n",
        "        print(f\"✅ Image uploaded: {file_name} (Size: {image.size})\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error opening image: {e}\")\n",
        "        return\n",
        "\n",
        "    # Step 1: Classification\n",
        "    print(\"\\n🔍 Running classification...\")\n",
        "    pred_class, pred_prob = class_model.predict(image)\n",
        "\n",
        "    print(f\"📊 Classification Result: {pred_class} (Confidence: {pred_prob:.1%})\")\n",
        "\n",
        "    if pred_class == 'Normal':\n",
        "        print(\"✅ No stroke detected.\")\n",
        "        # Display original image\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title('Original CT Image - No Stroke')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    # Step 2: Segmentation\n",
        "    print(\"\\n🔬 Running segmentation...\")\n",
        "    pred_mask, stroke_ratio = seg_model.predict(image)\n",
        "\n",
        "    print(f\"📊 Segmentation Result: Stroke Area: {stroke_ratio:.1%}\")\n",
        "\n",
        "    # Stroke confirmation\n",
        "    is_stroke = stroke_ratio >= config.STROKE_DETECTION_THRESHOLD\n",
        "    final_diagnosis = pred_class if is_stroke else 'Normal'\n",
        "\n",
        "    print(f\"\\n🏥 FINAL DIAGNOSIS: {final_diagnosis} Stroke\")\n",
        "\n",
        "    # Display results\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    # Original image\n",
        "    ax1.imshow(image, cmap='gray')\n",
        "    ax1.set_title('Original CT Image')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Segmented image\n",
        "    overlay = create_overlay(image, pred_mask)\n",
        "    ax2.imshow(overlay)\n",
        "    ax2.set_title(f'Segmented Image - {final_diagnosis}')\n",
        "    ax2.text(10, 30, f'Confidence: {pred_prob:.1%}\\nStroke Area: {stroke_ratio:.1%}',\n",
        "             bbox={'facecolor': 'white', 'alpha': 0.7, 'pad': 5})\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    test = 0\n",
        "    while(test == 0):\n",
        "        print(\"Enter 0 to test\\nEnter 1 to exit\")\n",
        "        test = int(input())\n",
        "        if (test == 1):\n",
        "          print(\"User Exited\")\n",
        "          break\n",
        "        process_ct_image()"
      ],
      "metadata": {
        "id": "nyK6LGzu5IjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}